\chapter{Одновременное оценивание движения ВС и систематических ошибок. Алгоритмы параллельной фильтрации процессов, связанных через измерения}
\renewcommand{\headtext}{\thechapter.~Одновременное оценивание движения ВС и систематических ошибок}

\newcommand{\argmin}[1]{\underset{#1}{\mathrm{argmin}}} 
\newcommand{\argmax}[1]{\underset{#1}{\mathrm{argmax}}} 
\newcommand{\cov}[1]{\mathbb{C}\mathbf{ov}\!\left\{ #1 \right\}}
\newcommand{\expect}[1]{\mathbb{E}\!\left\{ #1 \right\}}
\newcommand{\probab}[1]{\mathbf{P}\!\left\{ #1 \right\}}
\newcommand{\tr}[1]{\mathrm{tr}\!\left\{ #1 \right\}}
\newenvironment{mymatrix}[1]{\left[\begin{array}{#1}}{\end{array}\right]}
\newcommand{\transp}[1]{{#1}^\mathsf{T}}

В настоящее время в системах УВД для определения параметров движения воздушных судов 
(координаты, скорости, ускорения и т.д.) используются алгоритмы линейного рекуррентного оценивания, 
близкие по используемой математической технике к фильтру Калмана. 
В качестве основного метода применяется алгоритм IMM. 
Главная особенность состоит в том, 
что задача оценки параметров движения для всех ВС, нахоящихся в зоне наблюдения, 
решается независимо для каждого ВС. 
Это полностью соответствует представлению о том, 
что движение каждого ВС никак не зависит от движения других ВС. 
Также это удобно с точки зрения архитектуры программы, 
реализующей систему мультитраекторной обработки --- 
данные, описывающие каждое ВС, можно легко выделить в отдельный объект, 
который можно создавать, удалять и использовать, например, для сравнения 
со вновь поступающими не привязанными к конкретному ВС измернеиями. 
С точки зрения математических алгоритмов, такое разделение также удобно, 
поскольку позволяет оставаться в рамках расчётов в пространстве достаточно низкой размерности 
(4--6 для фильтра Калмана, 15--30 для IMM). 

Наблюдение за движением ВС производится с помощью радиотехнических средств: 
как правило это система из нескольких радиолокаторов и система АЗН-В. 
Реальные измерительные средства, помимо случайных ошибок измерений, 
имеют систематические ошибки. 
Случайные ошибки измерения изначально предусмотрены архитектурой алгоритмов 
рекуррентного оценивания, как фильтра Калмана, так и IMM. 
Систематические ошибки в случае не сложных вариантов их пространственной зависимости 
также легко могут быть включены в алгоритмы оценивания, 
но при их включении обнаруживается одно весьма существенное обстоятельство: 
систематические ошибки одного и того же измерительного средства 
присутствуют в уравнении наблюдения для разных воздушных судов. 
Так, в простом случае связи между неизвестными оцениваемыми состояниями и измерением РЛС 
возникает следующее линейное уравнение наблюдения: 
\begin{gather}
  z_{a \, l}(t) = C^\chi(t) \chi_a(t) + C^\varsigma(t) \varsigma_l(t) + D(t) w_l(t) \,. 
  \label{Bedin:eq:z-simple}
\end{gather}
Здесь $t$ --- момент времени; $a$ --- индекс, обозначающий номер воздушного судна (aircraft); 
$l$ --- индекс радиолокатора (locator); $z_{a l}$ --- вектор измерения; 
$\chi_a$ --- вектор параметров движения ВС; 
$\varsigma_l$ --- вектор параметров, характеризущий состояние РЛС; $w_l(t)$ --- текущая реализация 
случайной ошибки РЛС; $C^\chi(t)$, $C^\varsigma(t)$, $D(t)$ --- матрицы, характеризующие влияние 
каждого параметра на измерение. 

Из вида этого уравнения ясно, что систематическая ошибка локатора $l$ может быть 
оценена только совместно с параметрами движения ВС $a$. 
Но этот радиолокатор наблюдает не только это движение, 
также верно и обратное --- ВС $a$ наблюдается не только радиолокатором $l$. 
Фазовые переменные для разных движений оказываются <<сцепленными>> между собой 
через параметры систематических ошибок. 
Таким образом, система всех движений и всех систематических ошибок нуждается в совместном оценивании. 

Как будет показано далее, даже в простом случае неуправляемых движений, 
стандартные процедуры оптимального совместного оценивания --- 
фильтр Калмана, оценка Гаусса--Маркова --- приводят к соотношениям, 
в которых переменые, относящиеся к разным движениям и систематическим ошибкам, 
существенно связаны друг с другом. 
Это приводит к следующим неприятным последствиям: 
\begin{itemize}
  \item 
  нет возможности задать в программе отдельные объекты для движений разных ВС;
  \item
  затруднено создание и удаление движений;
  \item
  в вычислениях необходимо поддерживать большую матрицу ковариации ошибок оценивания, 
  (в которую входят все кросс-ковариации для ошибок оценивания между различными ВС, 
  между каждым ВС и каждым РЛС и т.д.) это выливается в большие затраты 
  по времени вычисления и по памяти. 
\end{itemize}
От требования, чтобы параметры оценивались оптимально, можно отказаться. 
При этом появляется возможность устранить нежелательные эффекты, указанные выше. 
Но в таком случае необходимо тщательно проектировать алгоритм оценивания, 
для того чтобы получаемые оценки были близки к неизвестным истинным параметрам. 

Целью исследования, излагаемого ниже, является создание алгоритма 
лёгкого для параллельной реализации по отдельным воздушным судам 
и при этом обладающего низким уровнем погрешности оценивания. 
Исследование логически продолжает исследование, изложенное в отчёте \cite{bibNitaOtchet2015-05}. 

\section{Описание задачи наблюдения за многими ВС}

Считаем, что каждое воздушное судно подчиняется независимому, 
но оди по структуре уравнению движения. 
Так движение ВС номер $i$ имеет описание 
\begin{gather*}
  d\chi_i(t) = f(t, \chi_i(t), u_i(t))dt + dv_{i}(t)\,, 
\end{gather*}
где $\chi_i$ --- вектор параметров движения ВС; 
$f$ --- функция, задающая скорости движения; 
$u_i(t)$ --- функция управления, специфичная для ВС $i$; 
$dv_{i}$ --- приращение случайного возмущения для непрерывного варианта динамики; 
само дифференциальное уравнение сформулировано, например, в смысле Ито. 
В силу того, что наблюдение за ВС ведётся <<в большом масштабе>>, 
вектор $\chi_i$ может содержать не очень большое число параметров, 
а функция $f$ может быть выбрана достаточно простой. 
Измерения при помощи РЛС производятся в дискретные моменты времени, 
поэтому дальше удобно иметь дело с дискретизированным вариантом системы. 
При этом разумно ограничиться динамикой, близкой к линейной 
\begin{gather}
  \chi_i(t_k) = A_i(t_k, \chi_i(t_{k - 1}), u_i(t_k)) \chi_i(t_{k - 1}) + B_i(t_k) v_i(t_k) \,. 
  \label{Bedin:eq:x-small-control-dynamics}
\end{gather}
Здесь $v_i$ --- случайное возмущение; 
$B_i$ --- матричная функция, формирующая влияние случайного возмущения на движение; 
$A_i$ --- матрица, формирующая вид движения системы, зависящая от текущего значения управления $u(t_k)$. 
Моменты времени $t_k$ принадлежат некоторому дискретному множеству $\mathcal{T}$ 
и, на самом деле, определяются по ходу развития движения, т.е. не являются заданными заранее. 

В программе мультирадарной обработки для метода IMM уравнения движения использываются именно в виде 
\eqref{Bedin:eq:x-small-control-dynamics}. 
Далее, будем рассматривать более простую линейную динамику без управления 
\begin{gather}
  \chi_i(t_k) = A_i(\mathcal{T}_k) \chi_i(t_{k - 1}) + B_i(t_k) v_i(t_k) \,. 
  \label{Bedin:eq:x-small-dynamics}
\end{gather}
Здесь $\mathcal{T}_k = \{ t_l \in \mathcal{T} \colon \; t_l \leqslant t_k \}$ --- 
множество моментов времени до текущего включительно. 

В качестве основного варианта при моделировании выбираем 
прямолинейное равномерное движение на плоскости 
\begin{gather}
  \chi_i(t_k) = 
  \begin{bmatrix}
    x_i(t_k) \\ 
    v_i(t_k)
  \end{bmatrix}
  \,, \qquad 
  x_i(t_k), v_i(t_k) \in \mathbb{R}^\mathsf{2} 
  \,, \qquad 
  A_i(\mathcal{T}_k) = 
  \begin{bmatrix}
    I_\mathsf{2 \times 2} & (t_k - t_{k - 1}) I_\mathsf{2 \times 2} \\ 
    0_\mathsf{2 \times 2} & I_\mathsf{2 \times 2}
  \end{bmatrix}
  \,, 
  \label{Bedin:eq:x-straight-line-dynamics}
\end{gather}
где $x_i$, $v_i$ обозначают векторы координат и скорости на плоскости $\mathbb{R}^\mathsf{2}$. 
Непосредственно в моделировании используется $B_i \equiv 0$, $v_i \equiv 0$. 

Формирование наблюдений $z_{i j}$ будем описывать следующим уравнением наблюдения, 
несколько более сложным, чем уравнение \eqref{Bedin:eq:z-simple}: 
\begin{gather}
  z_{i j}(t) = C^\chi_i(t_k) \chi_i(t_k) + 
  C^\varsigma_j(t_k, \chi_i(t_k)) \varsigma_j(t_k) + 
  D_j(t_k, \chi_i(t_k)) w_j(t_k) \,. 
  \label{Bedin:eq:z-small-dynamics}
\end{gather}
Матрицы $C^\varsigma_j$, $D_j$ для всех имеющих смысл случаев зависят от положения ВС, 
поэтому явно указывается зависимость от $\chi_i$. 
В качестве параметров $\varsigma_j$ могут выступать постоянная систематическая ошибка по дальности 
и азимуту, коэффициент линейной зависимости для систематической ошибки по дальности и т.д. 
Матрица $C^\varsigma_j$ описывает влияние этих неизвестных параметров на измерения. 

Для параметров $\varsigma_j$, характеризующих систематические ошибки РЛС, также введём динамику 
\begin{gather}
  \varsigma_j(t_k) = A^\varsigma_j(t_k) \varsigma_j(t_{k - 1}) + B^\varsigma_j(t_k) v^\varsigma_j(t_k) \,. 
  \label{Bedin:eq:s-small-dynamics}
\end{gather}
Матрица $B^\varsigma_i$ характеризует дрейф систематических ошибок со временем. 
Для моделирования будем принимать: 
\begin{gather}
  \varsigma_j = 
  \begin{bmatrix}
    \Delta^r_j \\ \Delta^\alpha_j 
  \end{bmatrix}
  \,, \qquad 
  A^\varsigma_j(t_k) \equiv I_{\mathsf{2 \times 2}} 
  \,, \qquad
  B^\varsigma_i(t_k) \equiv 0_{\mathsf{2 \times 2}}
  \,. 
  \label{Bedin:eq:s-const-dynamics}
\end{gather} 
Здесь $\Delta^r_j, \Delta^\alpha_j \in \mathbb{R}$ --- 
значения постоянных систематических ошибок по дальности и азимуту, соответственно.  
Подробно понятия систематических ошибок по дальности и азимуту введены в отчёте 
???. 

Рассмотрим общий фазовый вектор 
\begin{gather}
  \xi(t) = 
  \begin{bmatrix}
    \chi_1(t) \\ \chi_2(t) \\ \vdots \\ \chi_n(t) \\ \varsigma_1(t) \\ \varsigma_2(t) \\ \vdots \\ \varsigma_m(t) 
  \end{bmatrix}
  \,. 
  \label{Bedin:eq:x-s-vector}
\end{gather}
Здесь $n$ и $m$ --- количества наблюдаемых ВС и наблюдающих радиолокаторов. 
Уравнения \eqref{Bedin:eq:x-small-dynamics}, \eqref{Bedin:eq:s-small-dynamics} 
можно переписать как
\begin{multline}
  \xi(t_k) = A(\mathcal{T}_k) \xi(t_{k - 1}) + B(t_k) v(t_k) 
  = \\ = 
  \begin{bmatrix}
    A_1(\mathcal{T}_k) & & & & & 0 \\
     & \ddots & & & & \\
     & & A_n(\mathcal{T}_k) & & & \\ 
    & & & A^\varsigma_1(t_k) & & \\
    & & & & \ddots & \\
    0 & & & & & A^\varsigma_m(t_k) 
  \end{bmatrix}
  \begin{bmatrix}
    \chi_1(t_{k - 1}) \\ \vdots \\ \chi_n(t_{k - 1}) \\ 
    \varsigma_1(t_{k - 1}) \\ \vdots \\ \varsigma_m(t_{k - 1}) 
  \end{bmatrix}
  + \\ + 
  \begin{bmatrix}
    B_1(t_k) & & & & & 0 \\
     & \ddots & & & & \\
     & & B_n(t_k) & & & \\ 
    & & & B^\varsigma_1(t_k) & & \\
    & & & & \ddots & \\
    0 & & & & & B^\varsigma_m(t_k) 
  \end{bmatrix}
  \begin{bmatrix}
    v_1(t_k) \\ \vdots \\ v_n(t_k) \\ 
    v^\varsigma_1(t_k) \\ \vdots \\ v^\varsigma_m(t_k) 
  \end{bmatrix}
  \,,
  \label{Bedin:eq:x-s-big-dynamics}
\end{multline}
где матрицы $A$ и $B$ представляют собой блочно-диагональные матрицы, 
объединяющие все $A_i$, $A^\varsigma_i$ и $B_i$, $B^\varsigma_i$. 
Также будем использовать символы $A^\chi$, $A^\varsigma$, $B^\chi$, $B^\varsigma$ 
для обозначения верхнего и нижнего блоков матриц $A$ и $B$, 
соответствующих динамике переменных $\chi$ и $\varsigma$. 

Каждый момент времени $t_k \in \mathcal{T}$ свяжем с некоторым измерением 
$z_{i j}(t_k)$ положения ВС с номером $i$ при помощи радиолокатора $j$. 
Одновременное наблюдение одного ВС несколькими радиолокаторами 
(как и одновременное наблюдение одним радиолокатором нескольких самолётов) 
будем считать пренебрежимо редким событием и не будем вводить его в модель наблюдения. 
Запишем уравнение наблюдения в том виде, как оно должно применяться ко всему большому фазовому вектору. 
\begin{gather}
  z(t_k) = z_{i j}(t_k) = C(t_k, \xi(t_k)) \xi(t_k) + D(t_k, \xi(t_k)) w(t_k) 
  \,, \label{Bedin:eq:z-big-dynamics} \\ 
  C(t_k, \xi(t_k)) = 
  %\bordermatrix{
    %&   &        &   & i           &   &        &   &              n + j              &   &        &   \cr 
    %& 0 & \cdots & 0 & C^\chi_i(t_k) & 0 & \cdots & 0 & C^\varsigma_j(t_k, \chi_i(t_k)) & 0 & \cdots & 0 \cr
  %}
  %= \notag \\ 
  \begin{bmatrix}
    C^\chi(t_k) & C^\varsigma(t_k, \chi(t_k)) 
  \end{bmatrix}
  \,, \notag \\ 
  C^\chi(t_k) = 
  \bordermatrix{
    &   &        &   & i           &   &        &   \cr 
    & 0 & \cdots & 0 & C^\chi_i(t_k) & 0 & \cdots & 0 \cr
  }
  \,, \notag \\ 
  C^\varsigma(t_k, \chi(t_k))  = 
  \bordermatrix{
    &   &        &   &                  j              &   &        &   \cr 
    & 0 & \cdots & 0 & C^\varsigma_j(t_k, \chi_i(t_k)) & 0 & \cdots & 0 \cr
  }
  \,, \notag \\ 
  D(t_k, \xi(t_k)) = D_j(t_k, \chi_i(t_k))
  %\bordermatrix{
    %&   &        &   &   j                   &   &        &   \cr 
    %& 0 & \cdots & 0 & D_j(t_k, \chi_i(t_k)) & 0 & \cdots & 0 \cr
  %}
  \,, \qquad 
  w(t_k) = w_j(t_k) 
  \,. \notag 
\end{gather}

Как указывалось выше, для моделирования будем применять 
предположение постоянных систематических ошибок по дальности и азимуту. 
При этом будем использовать линеаризованную модель воздействия таких ошибок на измерения. 
Соответствующие матрицы $C^\chi(t_k)$, $C^\varsigma(t_k, \chi_i(t_k))$, $D(t_k, \chi_i(t_k))$ имеют вид: 
\begin{gather}
  C^\chi_i(t_k) \equiv 
  \begin{bmatrix}
    I_\mathsf{2 \times 2} & 0_\mathsf{2 \times 2}
  \end{bmatrix} 
  \,, \qquad 
  C^\varsigma_j(t_k, \chi_i(t_k)) = 
  \begin{bmatrix}
    \frac{1}{\left\lVert x_i(t_k) - x_j^\mathsf{R} \right\rVert} 
    (x_i(t_k) - x_j^\mathsf{R}) & 
    \Omega^{\pi / 2}_\mathsf{2 \times 2} 
    (x_i(t_k) - x_j^\mathsf{R})
  \end{bmatrix}
  \,, \notag \\ 
  D(t_k, \chi_i(t_k)) = 
  C^\varsigma_j(t_k, \chi_i(t_k)) 
  \,, \qquad 
  \Omega^{\pi / 2}_\mathsf{2 \times 2} = 
  \begin{bmatrix}
     0 & 1 \\ 
    -1 & 0 
  \end{bmatrix}
  \,. 
  \label{Bedin:eq:z-simple-C-D}
\end{gather}
Здесь $x_j^\mathsf{R}$ --- координаты точки стояния радиолокатора $j$; 
$\Omega^{\pi / 2}_\mathsf{2 \times 2}$ --- 
матрица поворота на угол $\frac{\pi}{2}$ против часовой стрелки 
на плоскости $\mathbb{R}^\mathsf{2}$ с учётом северо-восточной системы координат. 
Случайные ошибки 
\begin{gather*}
  w^\varsigma_j(t_k) = 
  \begin{bmatrix}
    w^r_j(t_k) \\ w^\alpha_j(t_k) 
  \end{bmatrix}
\end{gather*}
разделяются на случайные ошибки, действующие по дальности и азимуту. 

Для всех случайных ошибок считаем справедливыми свойства: 
\begin{gather}
  \expect{v_i(t_k)} = \expect{v^\varsigma_i(t_k)} = \expect{w_j(t_k)} = 0 
  \,, \label{Bedin:eq:v-w-properties} \\ 
  \cov{v_{i_1}(t_k), v_{i_2}(t_l)} = \delta_{k l} \delta_{i_1 i_2} V^\chi_{i_1} 
  \,, \qquad  
  \cov{w_{j_1}(t_k), w_{j_2}(t_l)} = \delta_{k l} \delta_{j_1 j_2} W_{j_1} 
  \,, \notag \\ 
  \cov{v^\varsigma_{j_1}(t_k), v^\varsigma_{j_2}(t_l)} = \delta_{k l} \delta_{j_1 j_2} V^\varsigma_{j_1} 
  \,, \qquad  
  \cov{v_{i}(t_k), w_{j}(t_l)} = 
  \cov{v^\varsigma_{j_1}(t_k), w_{j_2}(t_l)} = 
  \notag \\ 
  = \cov{v^\varsigma_{j}(t_k), v_{i}(t_l)} = 0 
  \,, \qquad 
  \forall i, i_1, i_2 \in 1, \ldots, n \,, \; 
  \forall j, j_1, j_2 \in 1, \ldots, m \,, \; 
  \forall t_k, t_l \in \mathcal{T} \,,  
  \notag
\end{gather}
где $\delta_{p q}$ --- символ Кронекера; 
$V^\chi_i$ --- постоянная матрица дисперсии случайных возмущений для уравнений движения; 
$V^\varsigma_j$ --- постоянная матрица дисперсии случайных возмущений 
для уравнения эволюции параметров радиолокатора $j$; 
$W_j$ --- постоянная матрица дисперсии случайных ошибок наблюдения для радиолокатора $j$. 
Матрицы ковариаций для больших столбцов $v$ и $w$ будем обозначать
\begin{multline*}
  V^\chi = 
  \begin{bmatrix}
    V^\chi_1 & & 0 \\ 
    & \ddots & \\ 
    0 & & V^\chi_n 
  \end{bmatrix}
  \,, \quad 
  V^\varsigma = 
  \begin{bmatrix}
    V^\varsigma_1 & & 0 \\ 
    & \ddots & \\ 
    0 & & V^\varsigma_m 
  \end{bmatrix}
  \,, \\ 
  V = 
  \begin{bmatrix}
    V^\chi & 0 \\
    0 & V^\varsigma
  \end{bmatrix}
  \,, \quad 
  W = 
  \begin{bmatrix}
    W_1 & & 0 \\ 
    & \ddots & \\ 
    0 & & W_m 
  \end{bmatrix}
  \,.  
\end{multline*}

Для моделирования будем применять $W_j$ вида: 
\begin{gather}
  W_j = 
  \begin{bmatrix}
    \sigma_{r j}^\mathsf{2} & 0 \\
    0 & \sigma_{\alpha j}^\mathsf{2} 
  \end{bmatrix}
  \,, 
  \label{Bedin:eq:w-cov}
\end{gather}
где $\sigma_{r j}$, $\sigma_{\alpha j}$ --- заданные среднеквадратичные отклонения 
для случайных ошибок наблюдения по дальности и азимуту, относящихся к радиолокатору $j$. 
Матрицы $V^\chi_i$ будем брать одинаковыми диагональными, также будем поступать и 
с матрицами $V^\varsigma_j$ (в данном случае не будем раскрывать подробный 
вид и смысл диагональных элементов, поскольку при моделировании эта матрица принималась равной нулю). 
\begin{gather}
  V^\chi_i = 
  \begin{bmatrix}
    \sigma_{x^1}^\mathsf{2} & & & 0 \\
    & \sigma_{x^2}^\mathsf{2} & & \\
    & & \sigma_{v^1}^\mathsf{2} & \\
    0 & & & \sigma_{v^2}^\mathsf{2}
  \end{bmatrix}
  \,, \qquad
  V^\varsigma_j = 
  \begin{bmatrix}
    \sigma_{\varsigma^1}^\mathsf{2} & & 0 \\
    & \ddots & \\
    0 & & \sigma_{\varsigma^q}^\mathsf{2} 
  \end{bmatrix}
  \,. 
  \label{Bedin:eq:v-cov}
\end{gather}

\section{Задача фильтрации}

Целью фильтрации является получение оценки $\hat{\xi}(t_k)$ фазового вектора 
$\xi$ на момент $t_k$ поступления последнего измерения. 
Предполагается, что оценка вычисляется как некоторая функция $\Xi$ 
от информации обо всех измерениях до этого момента времени: 
\begin{gather*}
  \hat{\xi}(t_k) = \Xi\bigl(\{z(t)\}_{t \in \mathcal{T}_k} \bigr) \,,
\end{gather*}
а также от априорной информации. 
Также предполагается, что задан некоторый критерий, по которому будет определяться качество оценивания. 
Популярным выбором является: 
\begin{gather}
  J(t_k) = \expect{\lVert h^\mathsf{T}(\hat{\xi}(t_k) - \xi(t_k))\rVert^\mathsf{2}} \,, 
  \label{Bedin:eq:crit}
\end{gather}
где $h^\mathsf{T}$ --- некоторая заданная линейная функция, 
выделяющая, например, некоторую часть координат из всего вектора, 
$\xi(t_k)$ --- истинное значение фазового вектора $\xi$ в момент времени $t_k$. 
Поскольку речь идёт об оценивании в присутствии случайных ошибок наблюдения, 
оценка $\hat{\xi}(t_k)$ является случайной величиной, 
и в критерии присутствует символ математического ожидания $\expect{\cdot}$. 

Наиболее простыми и разумными с точки зрения оптимальности 
являются линейные рекуррентные оценки с линейным прогнозированием: 
\begin{align}
  \bar{\xi}(t_k) & = A(\mathcal{T}_k) \hat{\xi}(t_{k - 1}) 
  \,, \label{Bedin:eq:recursive-est-pred} \\
  \hat{\xi}(t_k) & = L(t_k, R(t_k)) \bar{\xi}(t_k) + K(t_k, R(t_k)) z(t_k) 
  \,, \label{Bedin:eq:recursive-est-corr} \\ 
  R(t_k) & = \mathcal{F}(t_k, R(t_{k - 1}) 
  \,. \label{Bedin:eq:recursive-est-add-par} 
\end{align}
Здесь $L(t_k, R(t_k))$ и $K(t_k, R(t_k))$ --- матричные коэффициенты, 
выбираемые для каждого момента самостоятельно, и зависящие от параметров линейных уравнений 
\eqref{Bedin:eq:x-s-big-dynamics}, \eqref{Bedin:eq:z-big-dynamics}, 
а также от вектора дополнительных параметров $R(t_k)$, пересчитываемого отдельно по некоторму, 
уже в общем случае нелинейному, правилу \eqref{Bedin:eq:recursive-est-add-par}. 
Уравнение прогноза \eqref{Bedin:eq:recursive-est-pred} 
обеспечивает оптимальную по имеющейся информации $\hat{\xi}(t_{k - 1})$ 
оценку вектора $\xi(t_k)$ среди всех возможных оценок вообще. 
Т.е. при оптимальном выборе $\hat{\xi}(t_{k - 1})$ 
оценка $\bar{\xi}(t_k)$ является оптимальной среди всех оценок 
вектора $\xi(t_k)$ по измерениям, предшествующим моменту $t_k$. 
Уравнение \eqref{Bedin:eq:recursive-est-corr} называют уравнением коррекции. 
Его целью является получение новой оценки, учитывющий последнее измерение. 

Далее в тексте, если рассматриваемые величины 
$\hat{\xi}(t_k)$, $\bar{\xi}(t_k)$, $L(t_k, R(t_k))$, и~т.~д. 
относятся к одному и тому же моменту времени $t_k$, 
скобки с аргументами в некоторых случаях будут опускаться, 
если это не будет создавать двусмысленности. 

Популярным дополнительным условием является условие несмещённости оценки 
\begin{gather}
  \expect{\hat{\xi}(t_k)} = \expect{\xi(t_k)} \,, 
  \label{Bedin:eq:est-unbiased-random}
\end{gather}
которое в случае детерминированного фазового вектора $\xi$, 
например, в случае равенства нулю матрицы $B(t_k)$ в уравнении \eqref{Bedin:eq:x-s-big-dynamics}, 
принимает вид 
\begin{gather}
  \expect{\hat{\xi}(t_k)} = \xi(t_k) \,. 
  \label{Bedin:eq:est-unbiased-determ}
\end{gather}

Если оценка $\hat{\xi}(t_{k - 1})$ удовлетворяет условию \eqref{Bedin:eq:est-unbiased-random}, 
легко видеть, что и оценка $\bar{\xi}(t_k)$ ему удовлетворяет 
в силу уравнения \eqref{Bedin:eq:x-s-big-dynamics}. 
Для уравнения коррекции \eqref{Bedin:eq:recursive-est-corr} 
условие несмещённости \eqref{Bedin:eq:est-unbiased-random} приводит к следующему условию 
\begin{multline*}
  \expect{\hat{\xi}(t_k)} = 
  L \, \expect{\bar{\xi}(t_k)} + K \, \expect{z(t_k)} 
  = \\ = 
  L \, \expect{\xi(t_k)} 
  + K \, \expect{C(t_k, \xi(t_k)) \xi(t_k)} 
  + K \, \expect{D(t_k, \xi(t_k)) w(t_k)} 
  = \\ = 
  L \, \expect{\xi(t_k)} 
  + K \, \expect{C(t_k, \xi(t_k)) \xi(t_k)} 
  + K \, \expect{D(t_k, \xi(t_k))} \expect{w(t_k)} 
  = \\ = 
  L \, \expect{\xi(t_k)} 
  + K \, \expect{C(t_k, \xi(t_k)) \xi(t_k)} 
  \,, \\ \Longrightarrow 
  L \, \expect{\xi(t_k)} = I - K \, \expect{C(t_k, \xi(t_k)) \xi(t_k)} 
  \,, 
\end{multline*}
которое для случая матрицы $C$, не зависящей от $\xi$, или для случая, 
когда вектор $\xi$ является детерминированным, 
переходит в матричное условие 
\begin{gather}
  L(t_k, R(t_k)) = I - K(t_k, R(t_k)) \, C(t_k, \xi(t_k)) \,.  
  \label{Bedin:eq:est-unbiased-L}
\end{gather} 
В случае рассматриваемой нами модельной системы матрица $C$ очень слабо зависит от $\xi$. 
Так, заменив в выражении \eqref{Bedin:eq:z-simple-C-D} для матрицы $C^\varsigma_j(t_k, \xi(t_k))$ 
вектор $x_i(t_k)$ на $z_{i j}(t_k)$ или $\bar{x}_i(t_k)$ (часть прогнозной оценки $\bar{\xi}(t_k)$), 
мы получим близкое выражение, пригодное для использования в линейных алгоритмах. 
Далее, все алгоритмы будут рассматирваться с условием \eqref{Bedin:eq:est-unbiased-L} 
с приближенной заменой $x_i(t_k)$ на $\bar{x}_i(t_k)$ в матрице~$C$ --- 
это соответствует варианту Enhanced Kalman Filter (EKF) для нелинейной системы. 
При его подстановке в уравнение коррекции получается 
\begin{gather*}
  \hat{\xi}(t_k) = \bar{\xi}(t_k) + K(t_k, R(t_k)) \, 
  \left( z(t_k) - C(t_k, \bar{\xi}(t_k)) \, \bar{\xi}(t_k) \right) \, 
\end{gather*}
или в упрощённой записи
\begin{gather}
  \hat{\xi}(t_k) = \bar{\xi}(t_k) + K 
  \left( z(t_k) - C \, \bar{\xi}(t_k) \right) \,. 
  \label{Bedin:eq:recursive-est-corr-unbiased}
\end{gather}

Слагаемое $C(t_k, \bar{\xi}(t_k)) \, \bar{\xi}(t_k)$ 
можно проинтерпретировать как прогнозное измерение на момент $t_k$. 
Таким образом в выражении оценки \eqref{Bedin:eq:recursive-est-corr-unbiased} 
фигурирует разность между действительным и прогнозым измерениями. 

Далее, в разделах посвящённых алгоритмам параллельной фильтрации, 
поскольку все рассматриваемые соотношения касаются шага между моментами $t_{k - 1}$ и $t_k$, 
аргументы будут опускаться. Т.~е. будут приняты обозначения 
\begin{gather*}
  A = A(\mathcal{T}_k) \,, \qquad B = B(t_k) \,, \qquad 
  C = C(t_k, \bar{\xi}(t_k)) \,, \qquad D = D(t_k, \bar{\xi}(t_k)) \,. 
\end{gather*}

Введём обозначение для матрицы ковариаций ошибки оценивания для прогнозной оценки 
\begin{multline}
  \bar{P}(t_k) = \cov{\bar{\xi}(t_k) - \xi(t_k)} 
  = \\ = 
  \begin{bmatrix}
    \cov{\bar{\chi}_1(t_k) - \chi_1(t_k), \bar{\chi}_1(t_k) - \chi_1(t_k)} & 
    \cdots & 
    \cov{\bar{\chi}_1(t_k) - \chi_1(t_k), \bar{\varsigma}_m(t_k) - \varsigma_m(t_k)} \\  
    \vdots & \ddots & \vdots \\ 
    \cov{\bar{\varsigma}_m(t_k) - \varsigma_m(t_k), \bar{\chi}_1(t_k) - \chi_1(t_k)} & 
    \cdots & 
    \cov{\bar{\varsigma}_m(t_k) - \varsigma_m(t_k), \bar{\varsigma}_m(t_k) - \varsigma_m(t_k)}   
  \end{bmatrix}
  = \\ = 
  \begin{bmatrix}
    \bar{P}_{\chi_1 \chi_1}(t_k) & \cdots & \bar{P}_{\chi_1 \varsigma_m}(t_k) \\ 
    \vdots & \ddots & \vdots \\ 
    \bar{P}_{\varsigma_m \chi_1}(t_k) & \cdots & \bar{P}_{\varsigma_m \varsigma_m}(t_k)  
  \end{bmatrix}
  = 
  \begin{bmatrix}
    \bar{P}_{\chi \chi} & \bar{P}_{\chi \varsigma} \\ 
    \bar{P}_{\varsigma \chi} & \bar{P}_{\varsigma \varsigma}  
  \end{bmatrix}
  \label{Bedin:eq:est-cov-pred}
\end{multline} 
и для матрицы ковариации ошибки основной оценки по измерениям до момента $t_k$ включительно 
\begin{multline}
  \hat{P}(t_k) = \cov{\hat{\xi}(t_k) - \xi(t_k)} 
  = \\ = 
  \begin{bmatrix}
    \cov{\hat{\chi}_1(t_k) - \chi_1(t_k), \hat{\chi}_1(t_k) - \chi_1(t_k)} & 
    \cdots & 
    \cov{\hat{\chi}_1(t_k) - \chi_1(t_k), \hat{\varsigma}_m(t_k) - \varsigma_m(t_k)} \\  
    \vdots & \ddots & \vdots \\ 
    \cov{\hat{\varsigma}_m(t_k) - \varsigma_m(t_k), \hat{\chi}_1(t_k) - \chi_1(t_k)} & 
    \cdots & 
    \cov{\hat{\varsigma}_m(t_k) - \varsigma_m(t_k), \hat{\varsigma}_m(t_k) - \varsigma_m(t_k)}   
  \end{bmatrix}
  = \\ = 
  \begin{bmatrix}
    \hat{P}_{\chi_1 \chi_1}(t_k) & \cdots & \hat{P}_{\chi_1 \varsigma_m}(t_k) \\ 
    \vdots & \ddots & \vdots \\ 
    \hat{P}_{\varsigma_m \chi_1}(t_k) & \cdots & \hat{P}_{\varsigma_m \varsigma_m}(t_k)  
  \end{bmatrix}
  = 
  \begin{bmatrix}
    \hat{P}_{\chi \chi} & \hat{P}_{\chi \varsigma} \\ 
    \hat{P}_{\varsigma \chi} & \hat{P}_{\varsigma \varsigma}  
  \end{bmatrix}
  \,.
  \label{Bedin:eq:est-cov-corr}
\end{multline} 
Здесь символами $\bar{P}_{\chi \chi}$, $\bar{P}_{\chi \varsigma}$, $\bar{P}_{\varsigma \varsigma}$ 
и т.~д. обозначены большие блоки матриц, включающие все ковариации между соответствующими 
частями фазового вектора. Так, например,  
\begin{gather*}
  \hat{P}_{\chi \varsigma} = \cov{\hat{\chi}(t_k) - \chi(t_k), \hat{\varsigma}(t_k) - \varsigma(t_k)} \,. 
\end{gather*}

Приведём общие уравнения для эволюции этих матриц. 
В силу уравнения \eqref{Bedin:eq:x-s-big-dynamics} и \eqref{Bedin:eq:recursive-est-pred} справедливо 
\begin{gather*}
  \bar{\xi}(t_k) - \xi(t_k) = 
  A \hat{\xi}(t_{k - 1}) - A \xi(t_{k - 1}) - B v(t_k) = 
  A \left( \hat{\xi}(t_{k - 1}) - \xi(t_{k - 1}) \right) - B v(t_k) \,.
\end{gather*}
Следовательно, в силу независимости случайной ошибки динамики $v(t_k)$ и 
ошибок оценивания $\hat{\xi}(t_{k - 1}) - \xi(t_{k - 1})$, 
зависящих от случайных величин $v(t)$, $w(t)$ при $t \in \mathcal{T}_{k - 1}$, 
верно соотношение 
\begin{gather}
  \bar{P}(t_k) = 
  \expect{
    \left( \bar{\xi}(t_k) - \xi(t_k) \right)
    \left( \bar{\xi}(t_k) - \xi(t_k) \right)^\mathsf{T}
  }
  = 
  A \hat{P}(t_{k - 1}) A^\mathsf{T} + B V B^\mathsf{T}
  \,. 
  \label{Bedin:eq:est-cov-pred-evolution}
\end{gather}

Пусть выполнено условие несмещённости и уравнение коррекции \eqref{Bedin:eq:recursive-est-corr} 
переходит в \eqref{Bedin:eq:recursive-est-corr-unbiased}, 
тогда для произвольного матричного коэффициента $K$ (без разницы каким образом полученного) справедливо 
\begin{multline*}
  \hat{\xi}(t_k) - \xi(t_k) = 
  \bar{\xi}(t_k) - \xi(t_k) + 
  K \left( z(t_k) - C \hat{\xi}(t_k) \right) = \\ = 
  \bar{\xi}(t_k) - \xi(t_k) + 
  K \left( C \xi(t_k) + w(t_k) - C \hat{\xi}(t_k) \right) = 
  \left( I - K C \right) \left( \bar{\xi}(t_k) - \xi(t_k) \right) + 
  K w(t_k) \,. 
\end{multline*}
Так же как и при выводе соотношения для $\bar{P}(t_k)$, 
можно утверждать о независимости случайной ошибки наблюдения $w(t_k)$ и 
ошибок оценивания $\bar{\xi}(t_k) - \xi(t_k)$, так как последние зависят от 
случайных величин $v(t)$, $w(t)$ при $t \in \mathcal{T}_{k - 1}$ и от $v(t_k)$. 
Следовательно, верно соотношение 
\begin{multline}
  \hat{P}(t_k) = 
  \expect{
    \left( \hat{\xi}(t_k) - \xi(t_k) \right)
    \left( \hat{\xi}(t_k) - \xi(t_k) \right)^\mathsf{T}
  }
  = \\ = 
  (I - K C) \bar{P}(t_k) (I - K C)^\mathsf{T} + K W K^\mathsf{T}
  \label{Bedin:eq:est-cov-corr-evolution}
\end{multline}
известное как {\it формула Иозефа}. 

Для критерия \eqref{Bedin:eq:crit} известна формула 
\begin{gather}
  J(t_k) = \tr{h^\mathsf{T} \hat{P}(t_k) h} \,. 
  \label{Bedin:eq:crit-trace}
\end{gather}

\section{Уравнения оптимальной фильтрации}

Уравнения оптимальной фильтрации можно получить, минимизируя след матрицы $\hat{P}(t_k)$ 
в соотношении \eqref{Bedin:eq:est-cov-corr-evolution} варьированием различных матричных коэффициентов $K$. 
При этом выводится коэффициент $K^*(t_k)$ минимизирующий критерий на каждом шаге работы алгоритма. 
\begin{gather}
  K^*(t_k) = \bar{P}(t_k) C^\mathsf{T} 
  \left( C \bar{P}(t_k) C^\mathsf{T} + D W D^\mathsf{T} \right)^\mathsf{-1} 
  \,.
  \label{Bedin:eq:Kalman-gain}
\end{gather}
Интересно, что оптимальное значение $K^*$ подходит и для любого $h$ в формуле \eqref{Bedin:eq:crit-trace}, 
т.~е. соответствует равномерной по $h$ оценке. 

Полностью, с подстановкой соотношения \eqref{Bedin:eq:Kalman-gain}, уравнения рекуррентной фильтрации 
называются уравнениями фильтра Калмана (или реккуррентной оценки Гаусса-Маркова для случая $B = 0$). 
Приведём их полностью: 
\begin{align}
  \bar{\xi}(t_k) & = A \hat{\xi}(t_{k - 1}) 
  \,, \notag \\
  \bar{P}(t_k) & = A \hat{P}(t_{k - 1}) A^\mathsf{T} + B V B^\mathsf{T}
  \,, \notag \\ 
  \Lambda & = C \bar{P}(t_k) C^\mathsf{T} + D W D^\mathsf{T} 
  \,, \notag \\ 
  K^* & = \bar{P}(t_k) C^\mathsf{T} \Lambda^\mathsf{-1}
  \,, \notag \\ 
  \hat{\xi}(t_k) & = \bar{\xi}(t_k) + K^* 
  \left( z(t_k) - C \, \bar{\xi}(t_k) \right)  
  \,, \label{Bedin:eq:Kalman-filter} \\ 
  \hat{P}(t_k) & = 
  (I - K^* C) \bar{P}(t_k) (I - K^* C)^\mathsf{T} + K^* W K^{* \mathsf{T}}
  = \notag \\ 
  & = (I - K^* C) \bar{P}(t_k) = \bar{P}(t_k) - K^* \Lambda K^{* \mathsf{T}} 
  \,. \notag
\end{align}
Матрица $\Lambda$ является матрицей ковариации отклонения прогнозного измерения $C \bar{\xi}(t_k)$ 
от действительного измерения $z(t_k)$. 
Два последних равенства в формуле для $\hat{P}(t_k)$ широко известны в литературе по фильтру Калмана. 
Однако следует отдавать себе отчёт, что эти соотношения ориентированы на специфический выбор $K$, 
и в общем случае не верны. 

Отметим, что в качестве дополнительных параметров $R(t_k)$, по которым пересчитывается коэффициент $K$, 
в данном случае выступают прогнозная $\bar{P}(t_k)$ и действительная $\hat{P}(t_k)$ 
матрицы ковариаций ошибок оценивания. 

Рассмотрим важную особенность фильтра Калмана. 
Даже для изучаемой нами системы с её специфическим видом уравнения наблюдения 
\eqref{Bedin:eq:z-big-dynamics} и матрицы $C$ будет справедливо: 
\begin{gather*}
  \bar{P}(t_k) C^\mathsf{T} = 
  \begin{bmatrix}
    \bar{P}_{\cdot \chi_i}(t_k) (C^\chi_i)^\mathsf{T} & 
    \bar{P}_{\cdot \varsigma_j}(t_k) (C^\varsigma_j)^\mathsf{T} 
  \end{bmatrix}
  \,, 
\end{gather*} 
где под символами $\bar{P}_{\cdot \chi_i}$, $\bar{P}_{\cdot \varsigma_j}$ 
понимаются столбцы матрицы $\bar{P}$, соответствующие переменным $\chi_i$ и $\varsigma_j$. 
В коэффициенте $K^*$ активными (не равными нулю) 
являются все строки для всех движений ВС и всех параметров радиолокаторов, 
несмотря на то, что текущее измерение связано с конкретным ВС и конкретным радиолокатором. 
Т.~е. коррекция оценки $\bar{\xi}$ затрагивает все переменные, и коррекция матрицы ковариации $\bar{P}$
производится по всем строкам и столбцам. 
Это является общим свойством для фильтрации Калмана --- 
этап коррекции затрагивает все переменные и всю матрицу ковариаций. 

В отличие от этапа коррекции, на этапе прогноза (экстраполяции) 
в фильтре Калмана не происходит такого значительного <<перемешивания>> различных частей 
фазового вектора. 
Рассматриваемая нами система является системой с <<разделённой>> динамикой 
\eqref{Bedin:eq:x-s-big-dynamics}, в которой части фазового вектора $\chi_i$, $\varsigma_j$ 
эволюционируют независимо друг от друга. 
Легко проверить, что в силу специфического вида матриц $A$ и $B$ 
соотношения этапа прогноза \eqref{Bedin:eq:Kalman-filter} легко <<распараллеливаются>>: 
\begin{align}
  \bar{\xi}(t_k) & = A \hat{\xi}(t_{k - 1}) 
  \quad \Rightarrow \quad 
  &
  \bar{\chi}_i(t_k) & = A_i \hat{\chi}_i(t_{k - 1}) 
  \,, \notag \\
  & & 
  \bar{\varsigma}_j(t_k) & = A^\varsigma_j \hat{\varsigma}_j(t_{k - 1}) 
  \,, \label{Bedin:eq:est-KF-pred-parallel} \\ 
  \bar{P}(t_k) & = 
  A \hat{P}(t_{k - 1}) A^\mathsf{T} + B V B^\mathsf{T} 
  \quad \Rightarrow \quad 
  &
  \bar{P}_{\chi_i \chi_i}(t_k) & = 
  A_i \hat{P}_{\chi_i \chi_i}(t_{k - 1}) A_i^\mathsf{T} + 
  B_i V^\chi_i B_i^\mathbf{T} 
  \,, \notag \\ 
  & & 
  \bar{P}_{\varsigma_j \varsigma_j}(t_k) & = 
  A^\varsigma_j \hat{P}_{\varsigma_j \varsigma_j}(t_{k - 1}) A_j^{\varsigma \, \mathsf{T}} + 
  B^\varsigma_j V^\varsigma_j B_j^{\varsigma \, \mathsf{T}} 
  \,. 
  \notag
\end{align}
Таким образом, в задаче одновременного оценивания положения нескольких ВС и систематических ошибок РЛС, 
как и в других задачах с <<разделённой>> динамикой, главным препятствием 
к параллельному применению алгоритмов фильтрации является именно этап коррекции. 
Содержательно можно сказать, что коррекция систематических ошибок по итогам некоторого измерения 
вынуждает несколько изменить оценки положения всех ВС, которые были сделаны по предыдущей, 
до коррекции, оценке систематических ошибок. 

Рассмотрим соотношения фильтра Калмана в варианте, разделённом по фазовым переменным. 
Здесь и далее матрицы ковариаций разделяются на блоки, соответствующие 
частям фазового вектора $\chi$ и $\varsigma$: 
%\begin{gather*}
  %\bar{P} = 
  %\begin{bmatrix}
    %\bar{P}_{\chi \chi} & \bar{P}_{\chi \varsigma} \\ 
    %\bar{P}_{\varsigma \chi} & \bar{P}_{\varsigma \varsigma}  
  %\end{bmatrix}
  %\,, \qquad
  %\hat{P} = 
  %\begin{bmatrix}
    %\hat{P}_{\chi \chi} & \hat{P}_{\chi \varsigma} \\ 
    %\hat{P}_{\varsigma \chi} & \hat{P}_{\varsigma \varsigma}  
  %\end{bmatrix}
  %\,,
%\end{gather*}
%как и матрицы, входящие в уравнения динамики и уравнение наблюдения
%\begin{gather*}
  %
%\end{gather*}
Уравнение наблюдения:
\begin{gather*}
  z(t_k) = C^{\chi}_i \chi_i(t_k) + C^{\varsigma}_j \varsigma_j(t_k) + D_j w_j \,.
\end{gather*}

\noindent 
Фильтр для переменных, описывающих движение. 

\noindent Этап предсказания:
\begin{align*}
  \bar{\chi}(t_k) & = A^\chi \hat{\chi}(t_{k - 1}) 
  \,, \\
  \bar{P}_{\chi \chi}(t_k) & = 
    A^\chi \hat{P}_{\chi \chi}(t_{k - 1}) A^{\chi \, \mathsf{T}} + 
    B^\chi V^\chi B^{\chi \, \mathsf{T}} 
  \,. 
\end{align*}
Этап коррекции:
\begin{align}
  K_{\chi} & = 
  \left(
    \bar{P}_{\chi \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i + 
    \bar{P}_{\chi \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j
  \right) \Lambda^\mathsf{-1} 
  \,, \notag \\
  \hat{\chi}(t_k) & = \bar{\chi}(t_k) + 
  K_{\chi} \left( 
    z(t_k) - C^{\chi}_i \bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right) 
  \,, \label{Bedin:eq:part-KF-x-corr} \\
  \hat{P}_{\chi \chi}(t_k) & = 
  \bar{P}_{\chi \chi}(t_k) - K_{\chi} \Lambda K_{\chi}^\mathsf{T} 
  \,. \notag
\end{align} 

\noindent Фильтр для систематической ошибки. 

\noindent Этап предсказания:
\begin{align*}
  \bar{\varsigma}(t_k) & = 
  A^\varsigma \hat{\varsigma}(t_{k - 1}) 
  \,, \\
  \bar{P}_{\varsigma \varsigma}(t_k) & = 
  A^\varsigma \hat{P}_{\varsigma \varsigma}(t_{k - 1}) A^{\varsigma \, \mathsf{T}} + 
  B^\varsigma V^{\varsigma} B^{\varsigma \, \mathsf{T}}
  \,.
\end{align*}
Этап коррекции:
\begin{align}
  K_{\varsigma} & = 
  \left(
    \bar{P}_{\chi_i \varsigma}(t_k)^\mathsf{T} C^{\chi \, \mathsf{T}}_i + 
    \bar{P}_{\varsigma \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j 
  \right) \Lambda^\mathsf{-1}
  \,, \notag \\ 
  \hat{\varsigma}(t_k) & = 
  \bar{\varsigma}(t_k) + K_{\varsigma} \left( 
    z(t_k) - C^{\chi}_i \bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right)
  \,, \label{Bedin:eq:part-KF-s-corr} \\
  \hat{P}_{\varsigma \varsigma}(t_k) & = 
  \bar{P}_{\varsigma \varsigma}(t_k) - 
  K_{\varsigma} \Lambda K_{\varsigma}^\mathsf{T}
  \,. \notag
\end{align}
Обновление блока кросс-ковариации:
\begin{align*}
  \bar{P}_{\chi \varsigma}(t_k) & = A^\chi \hat{P}_{\chi \varsigma}(t_{k - 1}) A^{\varsigma \, \mathsf{T}}
  \,, \\
  \hat{P}_{\chi \varsigma}(t_k) & = \bar{P}_{\chi \varsigma}(t_k) - K_{\chi} \Lambda K_{\varsigma}^\mathsf{T}
  \,.
\end{align*} 
Для обоих фильтров используется одна матрица $\Lambda$:
\begin{multline}
  \Lambda = 
  C^{\chi}_i \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i + 
  C^{\chi}_i \bar{P}_{\chi_i \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j + 
  \\ + 
  C^{\varsigma}_j \bar{P}_{\chi_i \varsigma_j}(t_k)^\mathsf{T} C^{\chi \, \mathsf{T}}_i + 
  C^{\varsigma}_j \bar{P}_{\varsigma_j \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j + 
  D_j W_j D_j^\mathsf{T} \,.
  \label{Bedin:eq:part-KF-Lambda}
\end{multline} 

\section{Упрощеные алгоритмы оценивания по Henk Blom}

В статье \cite{Blom1993} также как и в данном отчёте рассматривается задача 
одновременного оценивания движения многих ВС и определения систематических ошибок. 
Приводятся варианты упрощения алгоритма фильтрации Калмана, 
показавшие хорошую работу на практике. 
В основе этих упрощений лежит простое предположение. 
Пусть мы рассматриваем уравнение коррекции \eqref{Bedin:eq:part-KF-x-corr}. 
Давайте при этом считать, что неизвестное $\varsigma$ на самом деле нам известно, 
т.~е. оценка $\bar{\varsigma}$ не является случайной величиной и совпадает с $\varsigma$. 
Это может быть дальнейшим образом обобщено тем, 
что ковариации $\bar{P}_{\chi \varsigma}$ и $\bar{P}_{\varsigma \varsigma}$ 
равны нулю при вычислении текущей оценки $\hat{\chi}$ переменной $\chi$ (т.~е. как бы не существуют). 
Это приводит к следующим приближённым формулам: 
\begin{gather}
  \bar{P}_{\chi \varsigma}(t_k) C^{\varsigma \, \mathsf{T}} = 
  \bar{P}_{\chi \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j = 0 
  \,, \qquad 
  \bar{P}_{\varsigma \varsigma}(t_k) = 0
  \,, \quad \Longrightarrow \quad \notag \\
  K_\chi(t_k) = 
  \bar{P}_{\chi \chi}(t_k) C^{\chi \, \mathsf{T}} \Lambda_\chi^\mathsf{-1} = 
  \bar{P}_{\chi \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i \Lambda_\chi^\mathsf{-1} 
  \,, 
  \label{Bedin:eq:part-KF-Blom-Kx} \\
  \Lambda_\chi 
  = 
  C^{\chi} \bar{P}_{\chi \chi}(t_k) C^{\chi \, \mathsf{T}} + 
  D W D^\mathsf{T} 
  = 
  C^{\chi}_i \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i + 
  D_j W_j D^\mathsf{T}_j  
  \,.
  \label{Bedin:eq:part-KF-Blom-Lambdax}
\end{gather} 

Рассмотрим формулу \eqref{Bedin:eq:part-KF-Blom-Kx}. 
Предположим, что все кросс-ковариации между параметрами движения $i$ 
и параметрами других движений равны нулю на момент, предшествующий коррекции: 
\begin{gather*}
  \bar{P}_{\chi_{i_1} \chi_i} = 0 \,, \quad \forall i_1 \neq i \,.
\end{gather*} 
Тогда при применении коэффициента $K_\chi$ из формулы \eqref{Bedin:eq:part-KF-Blom-Kx} справедливо 
\begin{gather}
  K_{\chi_{i_1}}(t_k) = 0 
  \,, \qquad 
  K_{\chi_i}(t_k) = 
  \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i \Lambda_\chi^\mathsf{-1} 
  \,. \label{Bedin:eq:part-KF-Blom-Kx-parallel}
\end{gather}
Подставляя это конкретное выражение для $K_\chi$ в уравнения \eqref{Bedin:eq:part-KF-x-corr}, 
получаем, что для всех $i_1 \neq i$ и любых $l = 1, \ldots, n$ справедливо 
\begin{align*}
  \hat{\chi}_{i_1}  = \bar{\chi}_{i_1} \,, \qquad 
  \hat{P}_{\chi_{i_1} \chi_l} = \bar{P}_{\chi_{i_1} \chi_l} \,. 
\end{align*} 
Это означает, что параметры движений $i_1 \neq i$ не изменяются при учёте измерения $z(t_k)$, 
изменению подвергается только параметры движения, которое непосредственно наблюдается. 
Кроме того, из этого следует, что кросс-ковариации между 
параметрами остальных движений и параметрами движения $i$ 
остаются равными нулю и после коррекции. 
Следовательно, если в начальный момент обеспечить для всех $i_1 \neq i_2$ 
нулевые кросс-ковариации
\begin{gather*}
  \bar{P}_{\chi_{i_1} \chi_{i_2}} = 0 \,,
\end{gather*} 
то и дальше они останутся нулевыми, а каждое движение можно будет обрабатывать 
отдельным фильтром в параллельном режиме. 

Аналогично можно поступать и в ходе коррекции $\varsigma$, 
считая при этом не случайными величинами текущие оценки $\bar{\chi}$ параметров движения ВС. 
Это приводит к приближённым соотношениям, аналогичным соотношениям 
\eqref{Bedin:eq:part-KF-Blom-Kx}, \eqref{Bedin:eq:part-KF-Blom-Lambdax}, 
записанным для параметров систематических ошибок $\varsigma$: 
\begin{gather}
  \bar{P}_{\varsigma \chi}(t_k) C^{\chi \, \mathsf{T}} = 
  \bar{P}_{\varsigma \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i = 0 
  \,, \qquad 
  \bar{P}_{\chi \chi}(t_k) = 0
  \,, \quad \Longrightarrow \quad \notag \\
  K_\varsigma(t_k) = 
  \bar{P}_{\varsigma \varsigma}(t_k) C^{\varsigma \, \mathsf{T}} \Lambda_\varsigma^\mathsf{-1} = 
  \bar{P}_{\varsigma \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j \Lambda_\varsigma^\mathsf{-1} 
  \,, 
  \label{Bedin:eq:part-KF-Blom-Ks} \\
  \Lambda_\varsigma 
  = 
  C^{\varsigma} \bar{P}_{\varsigma \varsigma}(t_k) C^{\varsigma \, \mathsf{T}} + 
  D W D^\mathsf{T} 
  = 
  C^{\varsigma}_j \bar{P}_{\varsigma_j \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j + 
  D_j W_j D^\mathsf{T}_j  
  \,.
  \label{Bedin:eq:part-KF-Blom-Lambdas}
\end{gather} 

В случае пересчёта коэффициента $K_\varsigma$ по правилу \eqref{Bedin:eq:part-KF-Blom-Ks} 
точно также как и для $\chi$ 
появляется возможность параллельного пересчёта отдельных параметров $\varsigma_j$. 
Для этого нужно лишь обеспечить, чтобы в начальный момент времени 
для кросс-ковариаций выполнялось условие 
\begin{gather*}
  \bar{P}_{\varsigma_1 \varsigma_2} = 0 \,. 
\end{gather*}

\subsection{Разделённые фильтры для фазового вектора и для систематической ошибки}

Опишем подробно соотношения параллельной фильтрации, 
с учётом упрощённого вычисления коэффициента $K_\chi$ по формулам 
\eqref{Bedin:eq:part-KF-Blom-Kx}, \eqref{Bedin:eq:part-KF-Blom-Lambdax} 
и коэффициента $K_\varsigma$ по формулам 
\eqref{Bedin:eq:part-KF-Blom-Ks}, \eqref{Bedin:eq:part-KF-Blom-Lambdas} 
Напомним, что уравнение наблюдения для текущего измерения выглядит следующим образом:
\begin{align*} 
  z(t_k) & = C^{\chi}_i \chi_i(t_k) + C^{\varsigma}_j \varsigma_j(t_k) + D_j w_j \,. 
\end{align*}

Фильтр для переменных $\chi_i$, описывающих движение. $i = 1, \ldots, n$. 

\noindent Этап предсказания:
\begin{align*}
  \bar{\chi}_i(t_k) & = A_i \hat{\chi}_i(t_{k - 1}) 
  \,, \\ 
  \bar{P}_{\chi_i \chi_i}(t_k) & = 
  A_i \hat{P}_{\chi_i \chi_i}(t_{k - 1}) A^{\mathsf{T}}_i + 
  B_i V^\chi_i B^{\mathsf{T}}_i
  \,. 
\end{align*}
Этап коррекции:
\begin{align*}
  \hat{\chi}_i(t_k) & = \bar{\chi}_i(t_k) + 
  K_{\chi_i} \left( 
    z(t_k) - C^{\chi}_i \bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right)
  \,, \\ 
  \hat{P}_{\chi_i \chi_i}(t_k) & = 
  \bar{P}_{\chi_i \chi_i}(t_k) - K_{\chi_i} \Lambda_{\chi_i} K_{\chi_i}^\mathsf{T}
  \,. 
\end{align*} 
Аппроксимация:
\begin{align*}
  K_{\chi_i} & = \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i \Lambda_{\chi_i}^\mathsf{-1} 
  \,, \\ 
  \Lambda_{\chi_i} & = 
  C^{\chi}_i \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i + 
  D_j W_j D_j^\mathsf{T}
  \,. 
\end{align*} 

\noindent
Фильтр для параметров систематической ошибки $\varsigma_j$. $j = 1, \ldots, m$. 

\noindent Этап предсказания:
\begin{align*}
  \bar{\varsigma}_j(t_k) & = A^\varsigma_j \hat{\varsigma}_j(t_{k - 1}) 
  \,, \\ 
  \bar{P}_{\varsigma_j \varsigma_j}(t_k) & = 
  A^\varsigma_j \hat{P}_{\varsigma_j \varsigma_j}(t_{k - 1}) A^{\varsigma \, \mathsf{T}}_j + 
  B^\varsigma_j V^{\varsigma}_j B^{\varsigma \, \mathsf{T}}_j
  \,. 
\end{align*}
Этап коррекции:
\begin{align*}
  \hat{\varsigma}_j(t_k) & = 
  \bar{\varsigma}_j(t_k) + K_{\varsigma_j} \left( 
    z(t_k) - C^{\chi}\bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right)
  \,, \\ 
  \hat{P}_{\varsigma_j \varsigma_j}(t_k) & = 
  \bar{P}_{\varsigma_j \varsigma_j}(t_k) - K_{\varsigma_j} \Lambda_{\varsigma_j} K_{\varsigma_j}^\mathsf{T}
  \,. 
\end{align*}
Аппроксимация:
\begin{align*}
  K_{\varsigma_j} & = 
  \bar{P}_{\varsigma_j \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j \Lambda_{\varsigma_j}^\mathsf{-1}
  \, \\ 
  \Lambda_{\varsigma_j} & = 
  C^{\varsigma}_j \bar{P}_{\varsigma_j \varsigma_j}(t_k) C^{\varsigma \, \mathsf{T}}_j + 
  D_j W_j D_j^\mathsf{T}
  \,. 
\end{align*}

\subsection{Фильтр Калмана для фазового вектора, макро-фильтр для систематической ошибки}

Кроме одновременного применения упрощённых формул 
\eqref{Bedin:eq:part-KF-Blom-Kx}, \eqref{Bedin:eq:part-KF-Blom-Lambdax}, 
\eqref{Bedin:eq:part-KF-Blom-Ks}, \eqref{Bedin:eq:part-KF-Blom-Lambdas} 
для коэффициентов $K_\chi$ и $K_\varsigma$ 
в статье \cite{Blom1993} приводится ещё один <<промежуточный>> вариант упрощения. 
В этом варианте рассматривается ситуация, когда за движением $i$ 
в некоторый момент $t_k$ одновременно наблюдают несколько радиолокаторов. 
Будем считать для простоты, что это радиолокаторы с номерами от 1 до $m' \leqslant m$. 
При этом упрощение и, как следствие, <<распараллеливание>> выполняется только для 
переменных $\chi_i$. 
Для параметров систематических ошибок $\varsigma_j$ принимаются дополнительные 
упрощающие формулы, позволяющие не пересчитывать кросс-ковариации $\bar{P}_{\varsigma \chi}$. 
Не останавливаясь на подробной интерпретации метода, приведём вычислительные соотношения.
%\begin{multline*}
  %\expect{
    %\left( z(t_k) - \bar{z}(t_k) \ right)
    %\left( \varsigma(t_k) - \bar{\varsigma}(t_k) \right)^\mathsf{T}
  %} = 0 
  %\Longrightarrow \,, \\ 
  %\expect{
    %\left( z(t_k) - \bar{z}(t_k) \right)
    %\left( \varsigma(t_k) - \bar{\varsigma}(t_k) \right)^\mathsf{T}
  %} 
  %= \\ = 
  %\expect{
    %\left( 
      %C^\chi (\chi(t_k) - \bar{\chi}(t_k)) + 
      %C^\varsigma (\varsigma(t_k) - \bar{\varsigma}(t_k)) 
    %\right)
    %\left( \varsigma(t_k) - \bar{\varsigma}(t_k) \right)^\mathsf{T}
  %} 
  %= \\ = 
  %C^\chi \bar{P}_{\chi \varsigma} + 
  %C^\varsigma \bar{P}_{\varsigma \varsigma} 
  %= 0
  %\,.
%\end{multline*}

Напоминаем, что уравнение наблюдения выглядит следующим образом: 
\begin{gather*}
  z(t_k) = C^{\chi}_i \chi_i(t_k) + C^{\varsigma}_j \varsigma_j(t_k) + D_j w_j \,. 
\end{gather*}

\noindent Фильтр для переменных, описывающих движение. \\

\noindent Этап предсказания:
\begin{align*} 
  \bar{\chi}_i(t_k) & = A_i \hat{\chi}_i(t_{k - 1}) 
  \,, \\ 
  \bar{P}_{\chi_i \chi_i}(t_k) & = 
  A_i \hat{P}_{\chi_i \chi_i}(t_{k - 1}) A_i^{\mathsf{T}} + B_i V^\chi_i B^{\mathsf{T}}_i
  \,.
\end{align*}
Этап коррекции:
\begin{align*}
  \hat{\chi}_i(t_k) & = \bar{\chi}_i(t_k) + K_{\chi_i} 
  \left( 
    z(t_k) - C^{\chi}_i \bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right)
  \,, \\ 
  \hat{P}_{\chi_i \chi_i}(t_k) & = 
  \bar{P}_{\chi_i \chi_i}(t_k) - K_{\chi_i} \Lambda_{\chi_i} K_{\chi_i}^\mathsf{T} 
  \,.
\end{align*} 
Аппроксимация:
\begin{align*}
  K_{\chi_i} & = \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i \Lambda_{\chi_i}^\mathsf{-1}
  \,, \\ 
  \Lambda_{\chi_i} & = C^{\chi}_i \bar{P}_{\chi_i \chi_i}(t_k) C^{\chi \, \mathsf{T}}_i + D_j W_j D_j^\mathsf{T}
  \,. 
\end{align*}

\noindent Фильтр для систематической ошибки. 

\noindent Этап предсказания:
\begin{align*}
  \bar{\varsigma}(t_k) & = A^\varsigma \hat{\varsigma}(t_{k - 1}) 
  \,, \\ 
  \bar{P}_{\varsigma \varsigma}(t_k) & = 
  A^\varsigma \hat{P}_{\varsigma \varsigma}(t_{k - 1}) A^{\varsigma \, \mathsf{T}} + 
  B^\varsigma V^{\varsigma} B^{\varsigma \, \mathsf{T}}
  \,. 
\end{align*}
Этап коррекции:
\begin{align*}
  \hat{\varsigma}(t_k) & = \bar{\varsigma}(t_k) + 
  K_{\varsigma} \left( 
    z(t_k) - C^{\chi}_i \bar{\chi}_i(t_k) - C^{\varsigma}_j \bar{\varsigma}_j(t_k) 
  \right)
  \,, \\ 
  \hat{P}_{\varsigma \varsigma}(t_k) & = 
  \bar{P}_{\varsigma \varsigma}(t_k) - K_{\varsigma} \Lambda_\varsigma K_{\varsigma}^\mathsf{T}
  \,. 
\end{align*} 
В вычислении матриц $K_{\varsigma}$ и $\Lambda_\varsigma$ 
используются аппроксимация члена $C^{\chi}\bar{P}_{\chi \varsigma}(t_k)$: 
\begin{align*}
  K_{\varsigma} & = 
  \left(
  \bar{P}_{\varsigma \varsigma}(t_k) C^{\varsigma \, \mathsf{T}} + H^\mathsf{T}
  \right) \Lambda_\varsigma^\mathsf{-1}
  \,, \\ 
  \Lambda_\varsigma & = 
  m' C^{\chi} \bar{P}_{\chi \chi}(t_k) C^{\chi \, \mathsf{T}} + 
  \sum \limits_{j_1, j_2 = 1}^{m'} 
    C^{\varsigma}_{j_1} \bar{P}_{\varsigma_{j_1} \varsigma_{j_2}}(t_k) C^{\varsigma \, \mathsf{T}}_{j_2} + 
  \sum \limits_{j = 1}^{m'}
  \left(
    H C^{\varsigma \, \mathsf{T}}_j + C^{\varsigma}_j H^\mathsf{T} + 
    D_j W_j D_j^\mathsf{T}
  \right)
  \,, 
\end{align*} 
где $H$ строится следующим образом:
\begin{align*}
  F_{\chi} & = 
  \sum_{j = 1}^{m'}(D_j W_j D_j^\mathsf{T})^\mathsf{-1}
  \,, \\ 
  F_{\varsigma} & = 
  \sum_{j = 1}^{m'}(D_j W_j D_j^\mathsf{T})^\mathsf{-1} C^{\varsigma}_j
  \,, \\ 
  H & = 
  -(F_{\chi}^\mathsf{T} F_{\chi})^\mathsf{-1} 
  F_{\chi}^\mathsf{T} F_{\varsigma} \bar{P}_{\varsigma \varsigma}(t_k)
  \,.
\end{align*} 

\section{Алгоритм оценивания на основе CI}

Ключевое отличие алгоритмов, предложенных Henk Blom в статье \cite{Blom1993}, 
от алгоритма фильтрации Калмана состоит в том, что матричный коэффициент фильтра $K$ 
не равен нулю только для тех переменных, 
которые непосредственно участвуют в уравнении наблюдения для текущего измерения. 
Это приводит к идее, что следует пытаться найти оптимальный фильтр, заранее удовлетворяющий такому свойству, 
которое в таком случае выступает как некоторое ограничение в задаче оптимизации. 

Пусть в рассматриваемый момент времени $t_k$ наблюдается движение с номером $i$ 
и задействован радиолокатор с номером $j$. Уравнение наблюдения имеет вид 
\begin{gather*}
  z(t_k) = C^{\chi}_i \chi_i(t_k) + C^{\varsigma}_j \varsigma_j(t_k) + D_j w_j \,. 
\end{gather*}
Перегруппируем и переобозначим переменные, входящие в фазовый вектор $\xi$
\begin{gather*}
  \xi(t_k) = 
  \begin{bmatrix}
    \chi_i \\ 
    \varsigma_j \\
    y
  \end{bmatrix}
  \,.
\end{gather*}
В переменную $y$ входят параметры всех остальных движений, кроме $i$-го, 
и параметры всех остальных радиолокаторов, кроме $j$-го. 
Несмотря на замену, оставим прежние обозначения для матриц, 
присутствующих в уравнении динамики и уравнении наблюдения. 
Новые матрицы могут быть получены из старых путём простых линейных преобразований. 
Прогнозная и скорректированная матрицы ковариаций ошибок оценивания разделяются на следующие блоки: 
\begin{gather*}
  \bar{P}(t_k) = 
  \begin{bmatrix}
    \bar{P}_{\chi_i \chi_i}       & \bar{P}_{\chi_i \varsigma_j}      & \bar{P}_{\chi_i y}      \\ 
    \bar{P}_{\varsigma_j \chi_i}  & \bar{P}_{\varsigma_j \varsigma_j} & \bar{P}_{\varsigma_j y} \\ 
    \bar{P}_{y \chi_i}            & \bar{P}_{y \varsigma_j}           & \bar{P}_{y y} 
  \end{bmatrix}
  \,, \qquad 
  \hat{P}(t_k) = 
  \begin{bmatrix}
    \hat{P}_{\chi_i \chi_i}       & \hat{P}_{\chi_i \varsigma_j}      & \hat{P}_{\chi_i y}      \\ 
    \hat{P}_{\varsigma_j \chi_i}  & \hat{P}_{\varsigma_j \varsigma_j} & \hat{P}_{\varsigma_j y} \\ 
    \hat{P}_{y \chi_i}            & \hat{P}_{y \varsigma_j}           & \hat{P}_{y y} 
  \end{bmatrix}
  \,. 
\end{gather*}

Рассматриваем коэффициенты фильтра $K$ следующего вида 
\begin{gather}
  K = 
  \begin{bmatrix}
    K_{\chi_i} \\ 
    K_{\varsigma_j} \\ 
    0
  \end{bmatrix}
  \,, 
  \label{Bedin:eq:CI-K-wo-y}
\end{gather}
т. е. не воздействующие в ходе коррекции на часть переменных $y$. 
Подставляя такой вид $K$ в формулу Йозефа \eqref{Bedin:eq:est-cov-corr-evolution}, 
получаем следующие выражения для диагональных блоков скорректированной матрицы ковариации $\hat{P}$: 
\begin{align}
  \hat{P}_{\chi_i \chi_i} 
  & = 
  \left( I - K_{\chi_i} C^\chi_i \right) 
  \bar{P}_{\chi_i \chi_i} 
  \left( I - K_{\chi_i} C^\chi_i \right)^\mathsf{T} 
  + \notag \\ 
  & + 
  \left( I - K_{\chi_i} C^\chi_i \right) 
  \bar{P}_{\chi_i \varsigma_j} 
  C^{\varsigma \, \mathsf{T}}_j K_{\chi_i}^\mathsf{T} 
  +
  K_{\chi_i} C^\varsigma_j
  \bar{P}_{\varsigma_j \chi_i} 
  \left( I - K_{\chi_i} C^\chi_i \right)^\mathsf{T} 
  + \notag \\ 
  & + 
  K_{\chi_i} C^\varsigma_j
  \bar{P}_{\varsigma_j \varsigma_j} 
  C^{\varsigma \, \mathsf{T}}_j K_{\chi_i}^\mathsf{T} 
  + 
  K_{\chi_i} D_j W_j D_j^\mathsf{T} K_{\chi_i}^\mathsf{T}
  \,, \label{Bedin:eq:CI-cov-x} \\ 
  \hat{P}_{\varsigma_j \varsigma_j} 
  & = 
  \left( I - K_{\varsigma_j} C^\varsigma_j \right) 
  \bar{P}_{\varsigma_j \varsigma_j} 
  \left( I - K_{\varsigma_j} C^\varsigma_j \right)^\mathsf{T} 
  + \notag \\ 
  & + 
  \left( I - K_{\varsigma_j} C^\varsigma_j \right) 
  \bar{P}_{\varsigma_j \chi_i} 
  C^{\chi \, \mathsf{T}}_i K_{\varsigma_j}^\mathsf{T} 
  +
  K_{\varsigma_j} C^\chi_i
  \bar{P}_{\chi_i \varsigma_j} 
  \left( I - K_{\chi_i} C^\chi_i \right)^\mathsf{T} 
  + \notag \\ 
  & + 
  K_{\varsigma_j} C^\chi_i
  \bar{P}_{\chi_i \chi_i} 
  C^{\chi \, \mathsf{T}}_i K_{\varsigma_j}^\mathsf{T} 
  + 
  K_{\varsigma_j} D_j W_j D_j^\mathsf{T} K_{\varsigma_j}^\mathsf{T}
  \,, \label{Bedin:eq:CI-cov-s} \\ 
  \hat{P}_{y y} & = \bar{P}_{y y} 
  \,, \label{Bedin:eq:CI-cov-y} 
\end{align}

Диагональные блоки рассмотрены по следующей причине. 
Для многих систем с <<разделённой>> динамикой имеют смысл критерии вида \eqref{Bedin:eq:crit-trace}, 
в которых каждая строка $h^\mathsf{T}$ выделяет лишь те переменные, 
которые относятся к какому-нибудь одному набору парметров --- либо $\chi_i$, либо $\varsigma_j$. 
Легко показать, что в таких случаях значение критерия зависит только от диагональных блоков. 
Отметим, что каждый блок зависит от своего коэффициента: 
блок для $\chi_i$ от $K_{\chi_i}$, а блок для $\varsigma_j$ --- от $K_{\varsigma_j}$. 
Это позволяет оптимизировать значения $K_{\chi_i}$ и $K_{\varsigma_j}$ независимо. 
Так, для $h^\mathsf{T} = I$: 
\begin{gather*}
  \min_{K_{\chi_i} , \, K_{\varsigma_j}} \tr{ \hat{P} } =
  \min_{K_{\chi_i}} \tr{ \hat{P}_{\chi_i \chi_i} } + 
  \min_{K_{\varsigma_j}} \tr{ \hat{P}_{\varsigma_j \varsigma_j} } \,. 
\end{gather*}

Соотношение \eqref{Bedin:eq:CI-cov-y} вместе с \eqref{Bedin:eq:CI-K-wo-y} подтверждает, 
что алгоритм фильтрации рассматриваемого типа не затрагивает остальные переменные, 
кроме $\chi_i$ и $\varsigma_j$. 
Однако это само по себе не приводит к возможности распараллеливания вычислений. 
Рассмотрим блок ковариаций \eqref{Bedin:eq:CI-cov-x}. 
Из вида формулы легко можно понять, что для корректного вычисления оптимального $K_{\chi_i}$ 
необходимо держать в памяти и всё время пересчитывать кросс-ковариации $\bar{P}_{\chi_i \varsigma_j}$, 
а значит и вычислять не только диагональные блоки, но и все $\hat{P}_{\chi_i \varsigma_j}$, 
что приводит к тем же самым трудностям, что и оптимальная фильтрация при помощи фильтра Калмана. 
Следовательно, требуется устранить влияние кросс-ковариаций $\bar{P}_{\chi_i \varsigma_j}$ 
на вычисления $K_{\chi_i}$ и при этом обеспечить не очень большое <<загрубление>>. 
